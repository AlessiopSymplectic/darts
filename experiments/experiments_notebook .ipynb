{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29080d9d",
   "metadata": {},
   "source": [
    "# Benchmarks experiments notebook\n",
    "This notebook is an accompanying notebook to the main script <code>experiments_scripts.py</code>. \n",
    "It can be used to tune the hyper-parameters ranges and for quick testing. To run this notebook and the script, first install <code>darts</code> and the [<code>ray</code> library](https://docs.ray.io/en/latest/ray-overview/installation.html). Install [<code>optuna</code> library](https://optuna.readthedocs.io/en/stable/installation.html) to use Optuna search algorithms.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24370ac",
   "metadata": {},
   "source": [
    "# read data, setup directories, transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63843c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from ray import tune\n",
    "\n",
    "from datetime import datetime\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from darts.utils.utils import series2seq\n",
    "from darts.dataprocessing.pipeline import Pipeline\n",
    "from darts.metrics import mse, mae, smape, rmse, mape, mase\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import Callback, EarlyStopping\n",
    "from darts import TimeSeries\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import ray\n",
    "from ray import tune, air\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "from darts.models.forecasting.regression_model import RegressionModel\n",
    "from darts.models.forecasting.torch_forecasting_model import (MixedCovariatesTorchModel, PastCovariatesTorchModel,\n",
    "                                                              FutureCovariatesTorchModel , TorchForecastingModel)\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.air import session\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from csv import DictWriter\n",
    "from darts.utils import missing_values\n",
    "from darts.utils.statistics import plot_pacf\n",
    "\n",
    "# data and models\n",
    "from darts.datasets import ETTh1Dataset, ElectricityDataset\n",
    "from darts.models import TCNModel, DLinearModel, NLinearModel, NHiTSModel, LightGBMModel, LinearRegressionModel\n",
    "from builders import MODEL_BUILDERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e800c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_MIN = 5\n",
    "IN_MAX = 30 \n",
    "\n",
    "def _params_LinearRegression(trial):\n",
    "\n",
    "    lags = trial.suggest_int(\"lags\", IN_MIN * PERIOD_UNIT, IN_MAX * PERIOD_UNIT)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, lags - PERIOD_UNIT)\n",
    "\n",
    "    add_encoders = trial.suggest_categorical(\"add_encoders\", [False, True])\n",
    "\n",
    "    return None\n",
    "\n",
    "def _params_LGBMModel(trial):\n",
    "\n",
    "    lags = trial.suggest_int(\"lags\", IN_MIN * PERIOD_UNIT, IN_MAX * PERIOD_UNIT)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, lags - PERIOD_UNIT)\n",
    "\n",
    "    boosting = trial.suggest_categorical(\"boosting\", [\"gbdt\", \"dart\"])\n",
    "    num_leaves = trial.suggest_int(\"num_leaves\", 2, 50)\n",
    "    max_bin = trial.suggest_int(\"max_bin\", 100, 500)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-8, 1e-1, log=True)\n",
    "    num_iterations = trial.suggest_int(\"num_iterations\", 50, 500)\n",
    "    add_encoders = trial.suggest_categorical(\"add_encoders\", [False, True])\n",
    "\n",
    "    return None\n",
    "\n",
    "def _params_NHITS(trial):\n",
    "    \n",
    "    in_len = trial.suggest_int(\"in_len\", IN_MIN * PERIOD_UNIT, IN_MAX * PERIOD_UNIT) \n",
    "    out_len = trial.suggest_int(\"out_len\", 1, in_len - PERIOD_UNIT)\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 2,5)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1,3)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 2,5)\n",
    "    activation = trial.suggest_categorical(\"activation\", \n",
    "                                          ['ReLU','RReLU', 'PReLU', 'Softplus', 'Tanh', 'SELU', 'LeakyReLU', 'Sigmoid'])\n",
    "    MaxPool1d = trial.suggest_categorical(\"MaxPool1d\", [False, True])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    \n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-3, log=True)\n",
    "    add_encoders = trial.suggest_categorical(\"add_encoders\", [False, True])\n",
    "    \n",
    "    constants = {\"layer_widths\": 512, \"pooling_kernel_sizes\": None,\n",
    "                \"n_freq_downsample\" : None, }\n",
    "\n",
    "    return constants\n",
    "\n",
    "def _params_NLINEAR(trial):\n",
    "    \n",
    "    in_len = trial.suggest_int(\"in_len\", IN_MIN * PERIOD_UNIT, IN_MAX * PERIOD_UNIT) \n",
    "    out_len = trial.suggest_int(\"out_len\", 1, in_len - PERIOD_UNIT)\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [False, True])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [False, True])\n",
    "    normalize = trial.suggest_categorical(\"normalize\", [False, True])\n",
    "    \n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-3, log=True)\n",
    "    add_encoders = trial.suggest_categorical(\"add_encoders\", [False, True])\n",
    "\n",
    "    return None\n",
    "\n",
    "def _params_DLINEAR(trial):\n",
    "\n",
    "    in_len = trial.suggest_int(\"in_len\", IN_MIN * PERIOD_UNIT, IN_MAX * PERIOD_UNIT) \n",
    "    out_len = trial.suggest_int(\"out_len\", 1, in_len - PERIOD_UNIT)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 5, 25)\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [False, True])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [False, True])\n",
    "    \n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-3, log=True)\n",
    "    add_encoders = trial.suggest_categorical(\"add_encoders\", [False, True])\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def _params_TCNMODEL(trial):\n",
    "    \n",
    "    in_len = trial.suggest_int(\"in_len\", IN_MIN * PERIOD_UNIT, IN_MAX * PERIOD_UNIT) \n",
    "    out_len = trial.suggest_int(\"out_len\", 1, in_len - PERIOD_UNIT)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 5, 25)\n",
    "    num_filters = trial.suggest_int(\"num_filters\", 5, 25)\n",
    "    weight_norm = trial.suggest_categorical(\"weight_norm\", [False, True])\n",
    "    dilation_base = trial.suggest_int(\"dilation_base\", 2, 4)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    \n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-3, log=True)\n",
    "    add_encoders = trial.suggest_categorical(\"add_encoders\", [False, True])\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "params_generators = {\n",
    "    TCNModel.__name__: _params_TCNMODEL,\n",
    "    DLinearModel.__name__:_params_DLINEAR,\n",
    "    NLinearModel.__name__:_params_NLINEAR,\n",
    "    NHiTSModel.__name__:_params_NHITS, \n",
    "    LightGBMModel.__name__:_params_LGBMModel, \n",
    "    LinearRegressionModel.__name__:_params_LinearRegression\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd36ac5",
   "metadata": {},
   "source": [
    "## configure experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bbe7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ETTh1Dataset\n",
    "model_cl = DLinearModel#LinearRegressionModel#LightGBMModel#DLinearModel#TCNModel #NHiTSModel#\n",
    "random_seed = 42 \n",
    "\n",
    "# data\n",
    "PERIOD_UNIT = 24 \n",
    "subset_size = int(365*1.5) * PERIOD_UNIT\n",
    "split = 0.7\n",
    "load_as_multivariate = False \n",
    "encoders_past = {\"datetime_attribute\": {\"past\": [\"month\", \"week\", \"hour\",\"dayofweek\"]},\n",
    "                \"cyclic\": {\"past\": [\"month\", \"week\", \"hour\", \"dayofweek\"]}} \n",
    "encoders_future = {\"datetime_attribute\": {\"future\": [\"month\", \"week\", \"hour\",\"dayofweek\"]},\n",
    "                    \"cyclic\": {\"future\": [\"month\", \"week\", \"hour\", \"dayofweek\"]}}\n",
    "\n",
    "encoders = encoders_future if issubclass(model_cl, (MixedCovariatesTorchModel, FutureCovariatesTorchModel,RegressionModel))\\\n",
    "            else encoders_past\n",
    "\n",
    "# model training\n",
    "fixed_params={\n",
    "    \"BATCH_SIZE\" : 1024,\n",
    "    \"MAX_N_EPOCHS\": 100,\n",
    "    \"NR_EPOCHS_VAL_PERIOD\": 1,\n",
    "    \"MAX_SAMPLES_PER_TS\": 1000, \n",
    "    \"RANDOM_STATE\": random_seed\n",
    "}\n",
    "\n",
    "train_with_metric = True #Â whether optimize models based on a metric or based on val_loss\n",
    "eval_metric = smape\n",
    "time_budget = 300 # in seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5852ea4",
   "metadata": {},
   "source": [
    "## setup logging directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd417d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix random states\n",
    "#https://pytorch.org/docs/stable/notes/randomness.html\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "exp_start_time = datetime.now()\n",
    "exp_name = f\"{model_cl.__name__}_{exp_start_time.strftime('%Y-%m-%d')}_pid{os.getpid()}_seed{random_seed}\"\n",
    "\n",
    "# create directories \n",
    "experiment_root = os.path.join(os.getcwd(), f\"benchmark_experiments/{dataset.__name__}\")\n",
    "experiment_dir = os.path.join(os.getcwd(), f\"{experiment_root}/{exp_name}\")\n",
    "print(experiment_dir)\n",
    "os.makedirs(experiment_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf30fab",
   "metadata": {},
   "source": [
    "## read data and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21425ac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#read data \n",
    "if \"multivariate\" in dataset.__init__.__code__.co_varnames:\n",
    "    data = dataset(multivariate=load_as_multivariate).load()\n",
    "else:\n",
    "    data = dataset().load()\n",
    "\n",
    "data = series2seq(data)\n",
    "\n",
    "data = [\n",
    "    s[-subset_size:].astype(np.float32) for s in tqdm(data)\n",
    "]\n",
    "\n",
    "\n",
    "# split : train, validation , test (validation and test have same length)\n",
    "all_splits = [list(s.split_after(split)) for s in data]\n",
    "train_original = [split[0] for split in all_splits]\n",
    "vals = [split[1] for split in all_splits]\n",
    "vals = [list(s.split_after(0.5)) for s in vals]\n",
    "val_original = [s[0] for s in vals]\n",
    "test_original = [s[1] for s in vals]\n",
    "\n",
    "\n",
    "train_len = len(train_original[0])\n",
    "val_len = len(val_original[0])\n",
    "test_len = len(test_original[0])\n",
    "num_series = len(train_original)\n",
    "n_components = train_original[0].n_components\n",
    "\n",
    "print(\"number of series:\", num_series)\n",
    "print(\"number of components:\", n_components)\n",
    "print(\"training series length:\", train_len)\n",
    "print(\"validation series length:\", val_len)\n",
    "print(\"test series length:\", test_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf2959",
   "metadata": {},
   "source": [
    "## Check missing values and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e9cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if missing values and fill\n",
    "for i in range(num_series):\n",
    "    missing_ratio = missing_values.missing_values_ratio(train_original[i])\n",
    "    print(f\"missing values ratio in training series {i} = {missing_ratio}\")\n",
    "    print(\"filling training missing values by interpolation\")\n",
    "    if missing_ratio > 0.0:\n",
    "        missing_values.fill_missing_values(train_original[i])\n",
    "    \n",
    "    missing_ratio = missing_values.missing_values_ratio(val_original[i])\n",
    "    print(f\"missing values ratio in validation series {i} = {missing_ratio}\")\n",
    "    print(\"filling validation missing values by interpolation\")\n",
    "    if missing_ratio > 0.0:\n",
    "        missing_values.fill_missing_values(val_original[i])\n",
    "    \n",
    "    missing_ratio = missing_values.missing_values_ratio(test_original[i])\n",
    "    print(f\"missing values ratio in test series {i} = {missing_ratio}\")\n",
    "    print(\"filling test missing values by interpolation\")\n",
    "    if missing_ratio > 0.0:\n",
    "        missing_values.fill_missing_values(test_original[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a801ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = (\n",
    "        Scaler(scaler=MaxAbsScaler())\n",
    "        if issubclass(model_cl, TorchForecastingModel)\n",
    "        else None\n",
    "    )\n",
    "\n",
    "if scaler is not None:\n",
    "    train = scaler.fit_transform(train_original)\n",
    "    val = scaler.transform(val_original)\n",
    "    test = scaler.transform(test_original)\n",
    "else:\n",
    "    train = train_original\n",
    "    val = val_original\n",
    "    test = test_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492b219a",
   "metadata": {},
   "source": [
    "## plot some data and checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb324fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pick series and components at random to plot \n",
    "max_series_to_plot = 5\n",
    "max_comps_to_plot = 5\n",
    "\n",
    "\n",
    "if n_components < max_comps_to_plot:\n",
    "    max_comps_to_plot = n_components\n",
    "\n",
    "comps_vec = np.random.randint(0, n_components, max_series_to_plot)\n",
    "comp_names = train[0].columns.to_list()\n",
    "\n",
    "if num_series < max_series_to_plot:\n",
    "    max_series_to_plot = num_series\n",
    "\n",
    "print(\"all components:\", comp_names)\n",
    "series_vec = np.random.randint(0, num_series, max_series_to_plot)\n",
    "\n",
    "for idx in series_vec:\n",
    "    for comp_id in comps_vec:\n",
    "        comp_id = comp_names[comp_id]\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        val[idx][comp_id].plot()\n",
    "        plt.title(f\"{dataset.__name__}_{comp_id}_series{idx}\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        plot_pacf(val[idx][comp_id], max_lag = IN_MAX * PERIOD_UNIT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e209fafd",
   "metadata": {},
   "source": [
    "# setup optimiztation function and tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747158ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function \n",
    "\n",
    "def objective_val_loss(config, model_cl, encoders, fixed_params, train=train, val=val):\n",
    "\n",
    "    metrics = {\"metric\":\"val_loss\"}\n",
    "\n",
    "    tuner_callbacks = [TuneReportCallback(metrics, on=\"validation_end\")]\n",
    "\n",
    "    model = MODEL_BUILDERS[model_cl.__name__](**config, fixed_params= fixed_params, encoders = encoders, \n",
    "                                              callbacks=tuner_callbacks)\n",
    "\n",
    "    # train the model\n",
    "    if \"val_series\" in model.fit.__code__.co_varnames:\n",
    "        model.fit(\n",
    "            series=train,\n",
    "            val_series=val,\n",
    "            max_samples_per_ts=fixed_params[\"MAX_SAMPLES_PER_TS\"])\n",
    "    else:\n",
    "        model.fit(\n",
    "            series=train,\n",
    "            max_samples_per_ts=fixed_params[\"MAX_SAMPLES_PER_TS\"])\n",
    "\n",
    "    \n",
    "\n",
    "def objective_metric(config, model_cl, metric, encoders, fixed_params, train=train, val=val):\n",
    "    \n",
    "    model = MODEL_BUILDERS[model_cl.__name__](**config, encoders = encoders, fixed_params=fixed_params)\n",
    "\n",
    "    # train the model\n",
    "    if \"val_series\" in model.fit.__code__.co_varnames:\n",
    "        model.fit(\n",
    "            series=train,\n",
    "            val_series=val,\n",
    "            max_samples_per_ts=fixed_params[\"MAX_SAMPLES_PER_TS\"])\n",
    "    else:\n",
    "        model.fit(\n",
    "            series=train,\n",
    "            max_samples_per_ts=fixed_params[\"MAX_SAMPLES_PER_TS\"])\n",
    "\n",
    "    # DL Models : use best model for subsequent evaluation\n",
    "    if isinstance(model, TorchForecastingModel):\n",
    "        model = model_cl.load_from_checkpoint(model_cl.__name__, work_dir = os.getcwd(), best = True)\n",
    "\n",
    "    preds = model.predict(series=train, n=val_len)\n",
    "\n",
    "    \n",
    "    if metric.__name__ == \"mase\":\n",
    "        metric_evals = metric(val, preds, train, n_jobs=-1, verbose=True)\n",
    "    else:\n",
    "        metric_evals = metric(val, preds, n_jobs=-1, verbose=True)\n",
    "\n",
    "    metric_evals_reduced = np.mean(metric_evals) if metric_evals != np.nan else float(\"inf\")\n",
    "\n",
    "    session.report({\"metric\":metric_evals_reduced})\n",
    "    \n",
    "\n",
    "    \n",
    "objective_metric_with_params = tune.with_parameters(objective_metric, model_cl=model_cl, metric = eval_metric, \n",
    "                                            encoders = encoders, fixed_params=fixed_params, train=train, val=val)\n",
    "\n",
    "objective_val_loss_with_params = tune.with_parameters(objective_val_loss, model_cl=model_cl, \n",
    "                                            encoders = encoders, fixed_params=fixed_params, train=train, val=val)\n",
    "\n",
    "search_alg = OptunaSearch(\n",
    "    space = params_generators[model_cl.__name__],\n",
    "    metric= \"metric\",\n",
    "    mode= \"min\",\n",
    ")\n",
    "\n",
    "tuner =  tune.Tuner(\n",
    "            trainable=objective_metric_with_params if train_with_metric else objective_val_loss_with_params,\n",
    "            tune_config = tune.TuneConfig(\n",
    "                search_alg = search_alg,\n",
    "                num_samples = -1,\n",
    "                time_budget_s = time_budget,\n",
    "            ),\n",
    "            run_config = air.RunConfig(\n",
    "                                       local_dir = experiment_dir,\n",
    "                                       name = f\"{model_cl.__name__}_tuner_{eval_metric.__name__}\")\n",
    "        )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cba917",
   "metadata": {},
   "source": [
    "# run hyperparameters tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e0580",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run optimizer\n",
    "tuner_results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf684d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best results \n",
    "best_params = tuner_results.get_best_result(metric = \"metric\", mode = \"min\").config\n",
    "print(\"best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e909eb79",
   "metadata": {},
   "source": [
    "# train best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a9b72b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "best_model = MODEL_BUILDERS[model_cl.__name__](**best_params, \n",
    "                                               encoders = encoders,\n",
    "                                               fixed_params=fixed_params, work_dir=experiment_dir)\n",
    "\n",
    "if isinstance(best_model, TorchForecastingModel):\n",
    "    best_model.n_epochs = fixed_params[\"MAX_N_EPOCHS\"] + 50\n",
    "\n",
    "train_start_time= datetime.now()\n",
    "# train the model\n",
    "if \"val_series\" in best_model.fit.__code__.co_varnames:\n",
    "    best_model.fit(\n",
    "        series=train,\n",
    "        val_series=val,\n",
    "        max_samples_per_ts=fixed_params[\"MAX_SAMPLES_PER_TS\"],\n",
    "    )\n",
    "else:\n",
    "    best_model.fit(\n",
    "        series=train,\n",
    "        max_samples_per_ts=fixed_params[\"MAX_SAMPLES_PER_TS\"],\n",
    "    )\n",
    "train_end_time = datetime.now()\n",
    "training_time = (train_end_time - train_start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3232a8",
   "metadata": {},
   "source": [
    "# inference with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e314c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_start_time = datetime.now()\n",
    "test_predictions = best_model.predict(series = val, n = test_len)\n",
    "inference_end_time = datetime.now()\n",
    "inference_time = (inference_end_time - inference_start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b00ad9",
   "metadata": {},
   "source": [
    "## best model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d36285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_metric.__name__ == \"mase\":\n",
    "    metric_evals = eval_metric(test, test_predictions, train, n_jobs=-1, verbose=True)\n",
    "else:\n",
    "    metric_evals = eval_metric(test, test_predictions, n_jobs=-1, verbose=True)\n",
    "\n",
    "metric_evals_mean = np.mean(metric_evals) if metric_evals != np.nan else float(\"inf\")\n",
    "metric_evals_std= np.std(metric_evals)\n",
    "print(f\"{eval_metric.__name__} mean = {metric_evals_mean}, std = {metric_evals_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeef072",
   "metadata": {},
   "source": [
    "# plot forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5356b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pick series and components at random to plot \n",
    "max_series_to_plot = 5\n",
    "max_comps_to_plot = 5\n",
    "\n",
    "\n",
    "if n_components < max_comps_to_plot:\n",
    "    max_comps_to_plot = n_components\n",
    "\n",
    "comps_vec = np.random.randint(0, n_components, max_series_to_plot)\n",
    "comp_names = train[0].columns.to_list()\n",
    "\n",
    "if num_series < max_series_to_plot:\n",
    "    max_series_to_plot = num_series\n",
    "\n",
    "print(\"all components:\", comp_names)\n",
    "series_vec = np.random.randint(0, num_series, max_series_to_plot)\n",
    "\n",
    "for idx in series_vec:\n",
    "    for comp_id in comps_vec:\n",
    "        comp_id = comp_names[comp_id]\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        val[idx][comp_id][-(val_len//4):].plot()\n",
    "        test[idx][comp_id].plot(label='actual')\n",
    "        test_predictions[idx][comp_id].plot(label='forecast')\n",
    "        plt.title(f\"{dataset.__name__}_{comp_id}_series{idx}\")\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b0c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
